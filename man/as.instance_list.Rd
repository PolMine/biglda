% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/as.instance_list.R
\name{as.instance_list}
\alias{as.instance_list}
\alias{as.instance_list,partition_bundle-method}
\alias{as.instance_list,list-method}
\alias{as.instance_list,character-method}
\alias{instance_list_save}
\alias{instance_list_load}
\title{Interface to mallet topicmodelling.}
\usage{
as.instance_list(x, ...)

\S4method{as.instance_list}{partition_bundle}(x, p_attribute = "word", verbose = TRUE, min_length = 1L, ...)

\S4method{as.instance_list}{list}(x, corpus, p_attribute = "word")

\S4method{as.instance_list}{character}(x, regex = "[\\\\p{L}]+", tolower = FALSE, stopwords = NULL)

instance_list_save(x, filename = tempfile())

instance_list_load(filename)
}
\arguments{
\item{x}{A \code{partition_bundle} object.}

\item{...}{Arguments passed into `get_token_stream()` call (e.g. argument
`subset` to apply stopwords).}

\item{p_attribute}{The p_attribute to use, typically "word" or "lemma".}

\item{verbose}{A \code{logical} value, whether to be verbose.}

\item{min_length}{Minimum length of documents after removing stopwords.}

\item{corpus}{A CWB indexed corpus, defined either by corpus ID, or
\code{corpus} object.}

\item{regex}{A regular expression (length-one `character` vector) used by
Mallet Java code for splitting `character` vector into tokens.}

\item{tolower}{A `logical` value, whether to lowercase tokens (performed)
by Mallet Java code.}

\item{stopwords}{Either a path with a plain text file with stopwords (one per
line), or a `character` vector.}

\item{filename}{Where to store the Java-object.}
}
\description{
Functionality to support the following workflow (see examples): (a) Turn
\code{partition_bundle}-object into mallet instance list, (b) store the
resulting \code{jobjRef}-object, (c) run mallet topic modelling and (d)
turn ParallelTopicModel Java object into \code{LDA_Gibbs} object from
package \code{topicmodels}.
}
\details{
`instance_list_load()` will load a Java InstanceList object that has
  been saved to disk (e.g. by using the `instance_list_save()` function).
  The return value is a `jobjRef` object. Internally, the function reuses
  code of the function `load.mallet.instances()` from the R package `mallet`.
}
\examples{
 
# Preparations: Create instance list

if (!mallet_is_installed()) mallet_install()
library(polmineR)
use("polmineR")

speeches <- polmineR::as.speeches(
  "GERMAPARLMINI", 
  s_attribute_name = "speaker", 
  s_attribute_date = "date"
)

instance_list <- as.instance_list(speeches)
lda <- ParallelTopicModel(25, 5.1, 0.1)
lda$addInstances(instance_list)
# lda$getDocLengthCounts()
lda$setNumThreads(1L)
lda$setTopicDisplay(50L, 10L)
destfile <- tempfile()
lda$setSaveSerializedModel(50L, rJava::.jnew("java/lang/String", destfile))
lda$setNumIterations(150L)
lda$estimate()
lda$write(rJava::.jnew("java/io/File", destfile))

# Load topicmodel and turn it into LDA_Gibbs

lda2 <- mallet_load_topicmodel(destfile)
topicmodels_lda <- as_LDA(lda)
library(polmineR)
use("polmineR")
speeches <- as.speeches("GERMAPARLMINI", s_attribute_name = "speaker", s_attribute_date = "date")
speeches_instance_list <- as.instance_list(speeches, p_attribute = "word")

# Pass argument 'subset' to remove stopwords
terms_to_drop <- tm::stopwords("de")
speeches_instance_list <- as.instance_list(
  speeches,
  p_attribute = "word",
  subset = {!get(p_attribute) \%in\% bquote(.(terms_to_drop))}
)
speeches <- as.speeches("GERMAPARLMINI", s_attribute_name = "speaker", s_attribute_date = "date")
id_list <- p_attributes(speeches, p_attribute = "word", decode = FALSE)
instance_list <- as.instance_list(id_list, corpus = "GERMAPARLMINI", p_attribute = "word")
instances <- as.speeches("GERMAPARLMINI", s_attribute_name = "speaker", s_attribute_date = "date") \%>\%
  get_token_stream(p_attribute = "word", collapse = " ") \%>\% 
  unlist() \%>\%
  as.instance_list()
}
\author{
Andreas Blaette, David Mimno
}
